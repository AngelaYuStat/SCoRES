---
title: "Methods"
author: "Angela Yu"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Methods}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

## Definition of Inverse Set and Introduction of the Estimation Method
The identification of domain sets whose outcomes belong to predefined subsets can address fundamental risk assessment challenges in climatology and medicine. A  motivating example involves estimating geographical regions where average  difference between summer and winter temperatures exceed a certain benchmark,  which help policymakers focus on specific areas that are at higher risk for  effects of climate change.  

Mathematically, the target region correspond to the inverse image of $U \subset  \mathbb{R}$ under an unknown function $\mu: \mathcal{S} \to \mathbb{R}$, can be defined as 
$$
\mu^{-1}(U) = \{s \in S: \mu(s) \in U\}
$$
, with $U$ a pre-specified  subset of a real line $\mathbb{R}$ (e.g., $[c, \infty)$).  

A point estimator for the inverse set can be constructed as $\hat{\mu}_n^{-1}(U)$, where $\hat{\mu}_n$ is an empirical estimator of $\mu$ based on $n$ observations. To quantify the spatial uncertainty of this estimation, Sommerfeld et al. (2018)  introduced Coverage Probability Excursion (CoPE) sets, defined as: 
$$
\text{CS}_{\text{in}}(U) \subseteq \mu^{-1}(U) \subseteq \text{CS}_{\text{out}}(U)
$$
which satisfy: 
$$
\mathbb{P}\left(\text{CS}_{\text{in}}(U) \subseteq \mu^{-1}(U) \subseteq \text{CS}_{\text{out}}(U)\right) \geq 1 - \alpha
$$ 
for a pre-specified confidence level $1-\alpha$ (e.g., $\alpha = 0.05$).  

Existing approaches require restrictive assumptions, including domain density of $S$ in $R$, continuity of $\hat{\mu}_n$ and $\mu$ near thresholds, and  large-sample guarantees, which limit the applicability. Besides, the estimation  and coverage depend on setting a fixed threshold level, which is difficult to  determine.  

Ren et al. (2023) proposed a framework that generalizes the estimation of such  inverse sets to dense and non-dense domains with protection against inflated Type I error, and constructs multiple upper, lower or interval confidence sets of  $\mu^{-1}(U)$ over arbitrary chosen thresholds. The coverage probability is  achieved non-asymptotically and simultaneously through inverting simultaneous  confidence intervals. For instance, suppose we are interested in inverse set  $\mu^{-1}([c,\infty))$ for a single value $c$, the inverse confidence sets (CSs) are  constructed by inverting simultaneous confidence intervals (SCIs). Given SCI  bounds $\hat{B}_{l}(\boldsymbol{s})$ and $\hat{B}_{u}(\boldsymbol{s})$ satisfying:

$$
\mathbb{P}\left(\forall\boldsymbol{s}\in\mathcal{S}: \hat{B}_{l}(\boldsymbol{s}) \leq \mu(\boldsymbol{s}) \leq \hat{B}_{u}(\boldsymbol{s})\right) = 1-\alpha
$$

The inner and outer CSs for the inverse upper excursion set $$\mu^{-1}[c, \infty)$$ are defined as:  
$$
\text{CS}_{\text{in}}[c, \infty) := \hat{B}_\ell^{-1}[c, \infty)
$$

$$
\text{CS}_{\text{out}}[c,\infty) := \hat{B}_u^{-1}[c, \infty)
$$

The outer and inner confidence sets (CSs) for the inverse lower excursion set $\mu^{-1}\left(-\infty, c\right]$ are defined as:

$$
\text{CS}_{\text{in}}\left(-\infty, c\right] := \hat{B}_u^{-1}\left(-\infty, c\right]
= \left( \hat{B}_u^{-1}\left[c, +\infty\right) \right)^{\complement}
$$
$$
\text{CS}_{\text{out}}\left(-\infty, c\right] := \hat{B}_\ell^{-1}\left(-\infty, c\right]
= \left( \hat{B}_\ell^{-1}\left[c, +\infty\right) \right)^{\complement}
$$

The inner and outer CSs for the inverse interval set $\mu^{-1}[a, b]$ are defined as:

$$
\text{CS}_{\text{in}}[a, b] := \hat{B}_\ell^{-1}[a, \infty) \cap \hat{B}_u^{-1}(-\infty, b]
$$

$$
\text{CS}_{\text{out}}[a, b] := \hat{B}_u^{-1}[a, \infty) \cap \hat{B}_\ell^{-1}(-\infty, b]
$$

## Linear Function-on-Scalar Regression (FoSR)

A simple example for function-on-scalar regression model is

$$
Y_i(t) = \beta_0(t) + \beta_1(t) X_{i1} + b_i(t) + \epsilon_i(t),
$$

where:

- \( Y_i(t) \) is a functional outcome
- \( X_{i1} \) is a scalar covariate 
- Each \( \beta_j(t) \) is a coefficient function  
- \( b_i(t) \) is a subject-specific functional random effect. This captures correlation within subjects over time that is not captured by the mean. This term is not always included in FoSR models, but itâ€™s generally a good idea because it gives better inference  
- \( \epsilon_i(t) \) are normally distributed iid errors

Here, the same bases are used for \( \beta_1(t) \) and \( \beta_2(t) \).

### Accounting for Error Correlation

The fitted GAM model above didn't take the correlation of residuals into account. Here, we combined random effects and FPCA into the GAM model to resolve this.

#### Modeling residuals with FPCA and gam

First, fit the mean model:

$$
Y_i(t) = \beta_0(t) + \beta_1(t) X_{i1} + e_i(t),
$$

#### Estimate the FPCA for GAMM FPCA model

After obtaining residuals from the mean model, FPCA models the residuals using equation \(e_i(s) = b_i(s) + \epsilon_i(s)\), where \(b_i(s)\) 
follows a mean zero Gaussian Process (GP) with covariance function \(\Sigma\), and \(\epsilon_i(s)\) are independent \(N(0, \sigma_e^2)\) random errors.

Assuming that \(\phi_k(\cdot)\) are the eigenfunctions of the covariance operator 
\(K_X\) of \(b_i(\cdot)\), one can express:

$$
b_i(t) = \sum_{k=1}^{\infty} \xi_{ik} \phi_k(t)
$$

The GAMM-FPCA model will be :

$$
Y_i(t) = \beta_0(t) + \beta_1(t) X_{i1} + \sum_{k=1}^{K} \xi_{ik} \phi_k(t) + \epsilon_i(t),
$$

## Construction of Simultaneous Confidence Bands for Functional Regression Model

### Correlation and Multiplicity Adjusted (CMA) Confidence Bands Based on Parameter Simulations

1.  Simulate model parameters
    $\boldsymbol{\beta}_1, \ldots, \boldsymbol{\beta}_B \overset{\text{i.i.d.}}{\sim} \mathcal{N}(\hat{\boldsymbol{\beta}}, \hat{V}_{\boldsymbol{\beta}})$
, where
    $(\hat{\boldsymbol{\beta}}, \hat{V}_{\boldsymbol{\beta}})$
    are estimated via a fitted FoSR model.

2. For each $b = 1, \ldots, B$, compute
$$
   \mathbf{X}_b = \frac{\mathbf{B}({\beta}_b - \hat{{\beta}})}{\mathbf{D}_f}
$$
, where the division is element-wise and \( \mathbf{B} \) maps parameters to functional effects.

3. Let
$$
   d_b = \max(|\mathbf{X}_b|), \quad b = 1, \ldots, B
$$
, where the absolute value is taken element-wise.

4. Estimate $q(C_f, 1 - \alpha)$ as the $100 \cdot (1 - \alpha)$ percentile of $\{d_1, \ldots, d_B\}$.

### Multiplier-t Bootstrap Procedure for Constructing Confidence Bands

1. Compute residuals $R_1^N, \ldots, R_N^N$, where $R_n^N = \sqrt{\frac{N}{N - 1}} \left( Y_n - \hat{\mu}_N \right)$, and multipliers $g_1, \ldots, g_N \overset{\text{i.i.d.}}{\sim} g$ with $\mathbb{E}[g] = 0$ and $\mathrm{var}[g] = 1$.

2. Estimate $\hat{\epsilon}_N^*(s)$ from $g_1 Y_1(s), \ldots, g_N Y_N(s)$.

3. Compute 
$$
T^*(s) = \frac{1}{\sqrt{N}} \sum_{n=1}^N g_n \frac{R_n^N(s)}{\hat{\epsilon}_N^*(s)}
$$

4. Repeat steps 1 to 3 many times. Take the $(1 - \alpha) \cdot 100\%$ quantile of $\mathcal{L}^*$ to estimate $q_{\alpha, N}$.

For details of the algorithm, please refer to Telschow et al. (2019)

$\hat{\mu}_N$ will be estimated though using the **fitted mean value** from a functional regression model (e.g., using `mgcv::bam`).

In the multiplier bootstrap procedure, `SCoRES` supports three types of multiplier distributions, which is specified by `weights`:

- `"rademacher"`: $g_i \in \{-1, +1\}$ with equal probability
- `"gaussian"`: $g_i \sim \mathcal{N}(0, 1)$
- `"mammen"`: A two-point distribution with mean zero and variance one (see Mammen, 1993)

Default is `rademacher`.

Two options are available for estimating the standard error 
$\hat{\epsilon}_N^*(s_j)$, which is specified by `method_SD`:

- "regular" (empirical standard error based on residuals):
$$
  \hat{\epsilon}_N^*(s_j) = \sqrt{ \frac{1}{n} \sum_{i=1}^n \left( {Y}_i(s_j) - \hat{\beta}(s_j) \right)^2 / (n-1) }
$$.

- "t" (bootstrap second moment-based estimator):
$$
\hat{\epsilon}_N^*(s_j) = \sqrt{ \frac{N}{N-1} \left| \mathbb{E}_b\left[ {Y}^{b}(s_j)^2 \right] - \left( \mathbb{E}_b\left[ {Y}^{b}(s_j) \right] \right)^2 \right| }
$$
, where expectations are taken over bootstrap replicates and 
${Y}^{b}(s_j)$ is the perturbed sample in bootstrap iteration $b$. The absolute value ensures numerical stability when subtracting large, nearly equal quantities.
  
Default is `t`.
  
