<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Angela Yu" />

<meta name="date" content="2025-07-22" />

<title>Methods</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>







<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Methods</h1>
<h4 class="author">Angela Yu</h4>
<h4 class="date">2025-07-22</h4>


<div id="TOC">
<ul>
<li><a href="#definition-of-inverse-set-and-introduction-of-the-estimating-method" id="toc-definition-of-inverse-set-and-introduction-of-the-estimating-method"><span class="toc-section-number">1</span> Definition of Inverse Set and
Introduction of the Estimating Method</a></li>
<li><a href="#construction-of-simultaneous-confidence-bands-for-functional-regression-model" id="toc-construction-of-simultaneous-confidence-bands-for-functional-regression-model"><span class="toc-section-number">2</span> Construction of Simultaneous
Confidence Bands for Functional Regression Model</a></li>
</ul>
</div>

<div id="definition-of-inverse-set-and-introduction-of-the-estimating-method" class="section level2" number="1">
<h2><span class="header-section-number">1</span> Definition of Inverse
Set and Introduction of the Estimating Method</h2>
<p>The identification of domain sets whose outcomes belong to predefined
subsets can address fundamental risk assessment challenges in
climatology and medicine. A motivating example involves estimating
geographical regions where average difference between summer and winter
temperatures exceed a certain benchmark, which help policymakers focus
on specific areas that are at higher risk for effects of climate
change.</p>
<p>Mathematically, the target region correspond to the inverse image of
<span class="math inline">\(U \subset  \mathbb{R}\)</span> under an
unknown function <span class="math inline">\(\mu: \mathcal{S} \to
\mathbb{R}\)</span>, can be defined as <span class="math display">\[
\mu^{-1}(U) = \{s \in S: \mu(s) \in U\}
\]</span> , with <span class="math inline">\(U\)</span> a pre-specified
subset of a real line <span class="math inline">\(\mathbb{R}\)</span>
(e.g., <span class="math inline">\([c, \infty)\)</span>).</p>
<p>A point estimator for the inverse set can be constructed as <span class="math inline">\(\hat{\mu}_n^{-1}(U)\)</span>, where <span class="math inline">\(\hat{\mu}_n\)</span> is an empirical estimator of
<span class="math inline">\(\mu\)</span> based on <span class="math inline">\(n\)</span> observations. To quantify the spatial
uncertainty of this estimation, Sommerfeld et al. (2018) introduced
Coverage Probability Excursion (CoPE) sets, defined as: <span class="math display">\[
\text{CS}_{\text{in}}(U) \subseteq \mu^{-1}(U) \subseteq
\text{CS}_{\text{out}}(U)
\]</span> which satisfy: <span class="math display">\[
\mathbb{P}\left(\text{CS}_{\text{in}}(U) \subseteq \mu^{-1}(U) \subseteq
\text{CS}_{\text{out}}(U)\right) \geq 1 - \alpha
\]</span> for a pre-specified confidence level <span class="math inline">\(1-\alpha\)</span> (e.g., <span class="math inline">\(\alpha = 0.05\)</span>).</p>
<p>Existing approaches require restrictive assumptions, including domain
density of <span class="math inline">\(S\)</span> in <span class="math inline">\(R\)</span>, continuity of <span class="math inline">\(\hat{\mu}_n\)</span> and <span class="math inline">\(\mu\)</span> near thresholds, and large-sample
guarantees, which limit the applicability. Besides, the estimation and
coverage depend on setting a fixed threshold level, which is difficult
to determine.</p>
<p>Ren et al. (2023) proposed a framework that generalizes the
estimation of such inverse sets to dense and non-dense domains with
protection against inflated Type I error, and constructs multiple upper,
lower or interval confidence sets of <span class="math inline">\(\mu^{-1}(U)\)</span> over arbitrary chosen
thresholds. The coverage probability is achieved non-asymptotically and
simultaneously through inverting simultaneous confidence intervals. For
instance, suppose we are interested in inverse set <span class="math inline">\(\mu^{-1}([c,\infty))\)</span> for a single value
<span class="math inline">\(c\)</span>, the inverse confidence sets
(CSs) are constructed by inverting simultaneous confidence intervals
(SCIs). Given SCI bounds <span class="math inline">\(\hat{B}_{l}(\boldsymbol{s})\)</span> and <span class="math inline">\(\hat{B}_{u}(\boldsymbol{s})\)</span>
satisfying:</p>
<p><span class="math display">\[
\mathbb{P}\left(\forall\boldsymbol{s}\in\mathcal{S}:
\hat{B}_{l}(\boldsymbol{s}) \leq \mu(\boldsymbol{s}) \leq
\hat{B}_{u}(\boldsymbol{s})\right) = 1-\alpha
\]</span></p>
<p>The inner and outer CSs for the inverse upper excursion set <span class="math display">\[\mu^{-1}[c, \infty)\]</span> are defined
as:<br />
<span class="math display">\[
\text{CS}_{\text{in}}[c, \infty) := \hat{B}_\ell^{-1}[c, \infty)
\]</span></p>
<p><span class="math display">\[
\text{CS}_{\text{out}}[c,\infty) := \hat{B}_u^{-1}[c, \infty)
\]</span></p>
<p>The outer and inner confidence sets (CSs) for the inverse lower
excursion set <span class="math inline">\(\mu^{-1}\left(-\infty,
c\right]\)</span> are defined as:</p>
<p><span class="math display">\[
\text{CS}_{\text{in}}\left(-\infty, c\right] :=
\hat{B}_u^{-1}\left(-\infty, c\right]
= \left( \hat{B}_u^{-1}\left[c, +\infty\right) \right)^{\complement}
\]</span> <span class="math display">\[
\text{CS}_{\text{out}}\left(-\infty, c\right] :=
\hat{B}_\ell^{-1}\left(-\infty, c\right]
= \left( \hat{B}_\ell^{-1}\left[c, +\infty\right) \right)^{\complement}
\]</span></p>
<p>The inner and outer CSs for the inverse interval set <span class="math inline">\(\mu^{-1}[a, b]\)</span> are defined as:</p>
<p><span class="math display">\[
\text{CS}_{\text{in}}[a, b] := \hat{B}_\ell^{-1}[a, \infty) \cap
\hat{B}_u^{-1}(-\infty, b]
\]</span></p>
<p><span class="math display">\[
\text{CS}_{\text{out}}[a, b] := \hat{B}_u^{-1}[a, \infty) \cap
\hat{B}_\ell^{-1}(-\infty, b]
\]</span> ## Linear Function-on-Scalar Regression (FoSR)</p>
<p>A simple example for function-on-scalar regression model is</p>
<p><span class="math display">\[
Y_i(t) = \beta_0(t) + \beta_1(t) X_{i1} + b_i(t) + \epsilon_i(t),
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(Y_i(t)\)</span> is a functional
outcome</li>
<li><span class="math inline">\(X_{i1}\)</span> is a scalar
covariate</li>
<li>Each <span class="math inline">\(\beta_j(t)\)</span> is a
coefficient function<br />
</li>
<li><span class="math inline">\(b_i(t)\)</span> is a subject-specific
functional random effect. This captures correlation within subjects over
time that is not captured by the mean. This term is not always included
in FoSR models, but it’s generally a good idea because it gives better
inference<br />
</li>
<li><span class="math inline">\(\epsilon_i(t)\)</span> are normally
distributed iid errors</li>
</ul>
<p>Here, the same bases are used for <span class="math inline">\(\beta_1(t)\)</span> and <span class="math inline">\(\beta_2(t)\)</span>.</p>
<div id="accounting-for-error-correlation" class="section level3" number="1.1">
<h3><span class="header-section-number">1.1</span> Accounting for Error
Correlation</h3>
<p>The fitted GAM model above didn’t take the correlation of residuals
into account. Here, we combined random effects and FPCA into the GAM
model to resolve this.</p>
<div id="modeling-residuals-with-fpca-and-gam" class="section level4" number="1.1.1">
<h4><span class="header-section-number">1.1.1</span> Modeling residuals
with FPCA and gam</h4>
<p>First, fit the mean model:</p>
<p><span class="math display">\[
Y_i(t) = \beta_0(t) + \beta_1(t) X_{i1} + e_i(t),
\]</span></p>
</div>
<div id="estimate-the-fpca-for-gamm-fpca-model" class="section level4" number="1.1.2">
<h4><span class="header-section-number">1.1.2</span> Estimate the FPCA
for GAMM FPCA model</h4>
<p>After obtaining residuals from the mean model, FPCA models the
residuals using equation <span class="math inline">\(e_i(s) = b_i(s) +
\epsilon_i(s)\)</span>, where <span class="math inline">\(b_i(s)\)</span> follows a mean zero Gaussian
Process (GP) with covariance function <span class="math inline">\(\Sigma\)</span>, and <span class="math inline">\(\epsilon_i(s)\)</span> are independent <span class="math inline">\(N(0, \sigma_e^2)\)</span> random errors.</p>
<p>Assuming that <span class="math inline">\(\phi_k(\cdot)\)</span> are
the eigenfunctions of the covariance operator <span class="math inline">\(K_X\)</span> of <span class="math inline">\(b_i(\cdot)\)</span>, one can express:</p>
<p><span class="math display">\[
b_i(t) = \sum_{k=1}^{\infty} \xi_{ik} \phi_k(t)
\]</span></p>
<p>The GAMM-FPCA model will be :</p>
<p><span class="math display">\[
Y_i(t) = \beta_0(t) + \beta_1(t) X_{i1} + \sum_{k=1}^{K} \xi_{ik}
\phi_k(t) + \epsilon_i(t),
\]</span></p>
</div>
</div>
</div>
<div id="construction-of-simultaneous-confidence-bands-for-functional-regression-model" class="section level2" number="2">
<h2><span class="header-section-number">2</span> Construction of
Simultaneous Confidence Bands for Functional Regression Model</h2>
<div id="correlation-and-multiplicity-adjusted-cma-confidence-bands-based-on-parameter-simulations" class="section level3" number="2.1">
<h3><span class="header-section-number">2.1</span> Correlation and
Multiplicity Adjusted (CMA) Confidence Bands Based on Parameter
Simulations</h3>
<ol style="list-style-type: decimal">
<li><p>Simulate model parameters <span class="math inline">\(\boldsymbol{\beta}_1, \ldots, \boldsymbol{\beta}_B
\overset{\text{i.i.d.}}{\sim} \mathcal{N}(\hat{\boldsymbol{\beta}},
\hat{V}_{\boldsymbol{\beta}})\)</span> , where <span class="math inline">\((\hat{\boldsymbol{\beta}},
\hat{V}_{\boldsymbol{\beta}})\)</span> are estimated via a fitted FoSR
model.</p></li>
<li><p>For each <span class="math inline">\(b = 1, \ldots, B\)</span>,
compute <span class="math display">\[
\mathbf{X}_b = \frac{\mathbf{B}({\beta}_b -
\hat{{\beta}})}{\mathbf{D}_f}
\]</span> , where the division is element-wise and <span class="math inline">\(\mathbf{B}\)</span> maps parameters to functional
effects.</p></li>
<li><p>Let <span class="math display">\[
d_b = \max(|\mathbf{X}_b|), \quad b = 1, \ldots, B
\]</span> , where the absolute value is taken element-wise.</p></li>
<li><p>Estimate <span class="math inline">\(q(C_f, 1 - \alpha)\)</span>
as the <span class="math inline">\(100 \cdot (1 - \alpha)\)</span>
percentile of <span class="math inline">\(\{d_1, \ldots,
d_B\}\)</span>.</p></li>
</ol>
</div>
<div id="multiplier-t-bootstrap-procedure-for-constructing-confidence-bands" class="section level3" number="2.2">
<h3><span class="header-section-number">2.2</span> Multiplier-t
Bootstrap Procedure for Constructing Confidence Bands</h3>
<ol style="list-style-type: decimal">
<li><p>Compute residuals <span class="math inline">\(R_1^N, \ldots,
R_N^N\)</span>, where <span class="math inline">\(R_n^N =
\sqrt{\frac{N}{N - 1}} \left( Y_n - \hat{\mu}_N \right)\)</span>, and
multipliers <span class="math inline">\(g_1, \ldots, g_N
\overset{\text{i.i.d.}}{\sim} g\)</span> with <span class="math inline">\(\mathbb{E}[g] = 0\)</span> and <span class="math inline">\(\mathrm{var}[g] = 1\)</span>.</p></li>
<li><p>Estimate <span class="math inline">\(\hat{\epsilon}_N^*(s)\)</span> from <span class="math inline">\(g_1 Y_1(s), \ldots, g_N Y_N(s)\)</span>.</p></li>
<li><p>Compute <span class="math display">\[
T^*(s) = \frac{1}{\sqrt{N}} \sum_{n=1}^N g_n
\frac{R_n^N(s)}{\hat{\epsilon}_N^*(s)}
\]</span></p></li>
<li><p>Repeat steps 1 to 3 many times. Take the <span class="math inline">\((1 - \alpha) \cdot 100\%\)</span> quantile of
<span class="math inline">\(\mathcal{L}^*\)</span> to estimate <span class="math inline">\(q_{\alpha, N}\)</span>.</p></li>
</ol>
<p>For details of the algorithm, please refer to Telschow et
al. (2019)</p>
<p><code>invSCI</code> provides two options for estimating the mean
function at <span class="math inline">\(s\)</span>, denoted as <span class="math inline">\(\hat{\mu}_N(s)\)</span>. If
<code>est_mean = TRUE</code>, the mean function will be estimated though
using the fitted regression object. If <code>est_mean = FALSE</code>,
sample mean will be calculated. Default is <code>FALSE</code>.</p>
<ol style="list-style-type: decimal">
<li><p>The <strong>sample mean</strong> <span class="math display">\[
\hat{\mu}_N(s) = \frac{1}{N} \sum_{i=1}^N {Y}_i(s)
\]</span> , where <span class="math inline">\({Y}_i(s)\)</span> is the
observed functional response.</p></li>
<li><p>The <strong>fitted mean value</strong> from a functional
regression model (e.g., using <code>mgcv::bam</code>).</p></li>
</ol>
<p>In the wild bootstrap procedure, <code>invSCI</code> supports three
types of multiplier distributions, which is specified by
<code>weights</code>:</p>
<ul>
<li><code>&quot;rademacher&quot;</code>: <span class="math inline">\(g_i \in \{-1,
+1\}\)</span> with equal probability</li>
<li><code>&quot;gaussian&quot;</code>: <span class="math inline">\(g_i \sim
\mathcal{N}(0, 1)\)</span></li>
<li><code>&quot;mammen&quot;</code>: A two-point distribution with mean zero and
variance one (see Mammen, 1993)</li>
</ul>
<p>Default is <code>rademacher</code>.</p>
<p>Two options are available for estimating the standard error <span class="math inline">\(\hat{\epsilon}_N^*(s_j)\)</span>, which is
specified by <code>method_SD</code>:</p>
<ul>
<li><p>“regular” (empirical standard error based on residuals): <span class="math display">\[
\hat{\epsilon}_N^*(s_j) = \sqrt{ \frac{1}{n} \sum_{i=1}^n \left(
{Y}_i(s_j) - \hat{\beta}(s_j) \right)^2 / (n-1) }
\]</span>.</p></li>
<li><p>“t” (bootstrap second moment-based estimator): <span class="math display">\[
\hat{\epsilon}_N^*(s_j) = \sqrt{ \frac{N}{N-1} \left| \mathbb{E}_b\left[
{Y}^{b}(s_j)^2 \right] - \left( \mathbb{E}_b\left[ {Y}^{b}(s_j) \right]
\right)^2 \right| }
\]</span> , where expectations are taken over bootstrap replicates and
<span class="math inline">\({Y}^{b}(s_j)\)</span> is the perturbed
sample in bootstrap iteration <span class="math inline">\(b\)</span>.
The absolute value ensures numerical stability when subtracting large,
nearly equal quantities.</p></li>
</ul>
<p>Default is <code>t</code>.</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
