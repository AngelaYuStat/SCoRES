y_hat_UB_global <- pred_df$mean + Z_global * pred_df$se
global_df <- list(
yhat = pred_df$mean,
time = s_pred,
se_hat = pred_df$se,
scb_low = y_hat_LB_global,
scb_uo = y_hat_UB_global,
type = "Global Confidence Interval (CMA)"
)
global_df <- as_tibble(global_df)  # 或者 data.frame(global_df)
ggplot(global_df, aes(x = time, y = yhat, color = type)) +
geom_line() +
geom_line(aes(y = scb_low), linetype = 2) +
geom_hline(yintercept = 0, linetype = 3, color = "red") +
theme_minimal() +
labs(
title = "Comparing Confidence Intervals for Non-user Group",
y = "yhat",
x = "Seconds",
color = "Interval Type"
)
summary(global_df)
dvec
yhat_boot
global_df <- list(
yhat = pred_df$mean,
time = s_pred,
se_hat = pred_df$se,
scb_low = y_hat_LB_global,
scb_up = y_hat_UB_global,
type = "Global Confidence Interval (CMA)"
)
global_df <- as_tibble(global_df)  # 或者 data.frame(global_df)
ggplot(global_df, aes(x = time, y = yhat, color = type)) +
geom_line() +
geom_line(aes(y = scb_low), linetype = 2) +
geom_hline(yintercept = 0, linetype = 3, color = "red") +
theme_minimal() +
labs(
title = "Comparing Confidence Intervals for Non-user Group",
y = "yhat",
x = "Seconds",
color = "Interval Type"
)
summary(global_df)
Z_global
lpmat <- predict(object, newdata=df_pred, se.fit=TRUE, type = "lpmatrix")
lpmat
mod_coef <- object$coefficients
if(model %in% c("gam", "bam")){
mod_cov <- vcov(object) # containing all variance-covariance info for object
}
# get all names for terms
coef_names <- names(mod_coef)
# get index of the initial terms
idx <- grep("^(Intercept)$|^s\\(seconds\\)\\.[0-9]+$", coef_names)
# initialize dataframe
predictors <- all.vars(formula(object))[-1]
df_pred <- as_tibble(
setNames(
lapply(predictors, function(x) 0),
predictors
)
)
if(!is.null(groups)){
# for group interested
groups_idx <- unlist(lapply(groups, function(g) grep(g, coef_names)))
idx <- sort(unique(c(idx, groups_idx)))
df_pred[groups] <- 1
}
if(!is.null(subject)){
df_pred[subject] <- as.character(model.frame(object)[[subject]][1])
}
if(is.null(range)){
s_pred <- unique(model.frame(object)[[time]])
}else{
s_pred <- sort(unique(range))
}
df_pred <- df_pred[rep(1, length(s_pred)), ]
df_pred[[time]] <- s_pred
# exract means and variance for group interested
mod_coef <- mod_coef[idx]
mod_cov <- mod_cov[idx, idx]
lpmat <- predict(object, newdata=df_pred, se.fit=TRUE, type = "lpmatrix")
dim(lpmat)
dim(mod_coef)
mod_coef
s_pred <- unique(ccds_for_gam$seconds)
mod_coef <- fosr_mod$coefficients # with Phi's
mod_cov <- vcov.gam(fosr_mod) # with Phi's
# get all names for terms
coef_names <- names(mod_coef)
# for use group
idx_use <- grep("s\\(seconds\\)", coef_names)
idx_use <- c(1, idx_use) #Intercept
# exract means and variance for beta0+beta1
mod_coef_use <- mod_coef[idx_use]
mod_cov_use <- mod_cov[idx_use, idx_use]
# for non use group
idx_non <- idx_use[!grepl("use", coef_names[idx_use])]
# exract means and variance for beta0
mod_coef_non <- mod_coef[idx_non]
mod_cov_non <- mod_cov[idx_non, idx_non]
# non-users
df_pred_non <- tibble(seconds = unique(ccds_for_gam$seconds),
use = 0, Phi1 = 0, Phi2 = 0, Phi3 = 0, Phi4 = 0,
subject = ccds_for_gam$subject[1])
lpmat_non <- predict(fosr_mod, newdata=df_pred_non, se.fit=TRUE, type = "lpmatrix") # with all use/phi terms equal to 0
# users
df_pred_use <- mutate(df_pred_non, use = 1)
lpmat_use <- predict(fosr_mod, newdata=df_pred_use, se.fit=TRUE, type = "lpmatrix")
# get mean response by group with standard errors
pred_df_non <- tibble(seconds = unique(ccds_for_gam$seconds),
user = c(rep("non-user", 401)),
mean = c(lpmat_non %*% mod_coef),
se = c(sqrt(diag(lpmat_non %*% mod_cov %*% t(lpmat_non))))) # get Df: take diag() to get the variance, here f_hat only contain estimates for fixed effect beta0
pred_df_use <- tibble(seconds = unique(ccds_for_gam$seconds),
user = c(rep("user", 401)),
mean = c(lpmat_use %*% mod_coef),
se = c(sqrt(diag(lpmat_use %*% mod_cov %*% t(lpmat_use))))) # get Df: take diag() to get the variance, here f_hat only contain estimates for fixed effects beta0 + beta1
dim(lpmat_non)
length(mod_coef)
mod_coef <- object$coefficients
if(model %in% c("gam", "bam")){
mod_cov <- vcov(object) # containing all variance-covariance info for object
}
# get all names for terms
coef_names <- names(mod_coef)
# get index of the initial terms
idx <- grep("^(Intercept)$|^s\\(seconds\\)\\.[0-9]+$", coef_names)
# initialize dataframe
predictors <- all.vars(formula(object))[-1]
df_pred <- as_tibble(
setNames(
lapply(predictors, function(x) 0),
predictors
)
)
if(!is.null(groups)){
# for group interested
groups_idx <- unlist(lapply(groups, function(g) grep(g, coef_names)))
idx <- sort(unique(c(idx, groups_idx)))
df_pred[groups] <- 1
}
if(!is.null(subject)){
df_pred[subject] <- as.character(model.frame(object)[[subject]][1])
}
if(is.null(range)){
s_pred <- unique(model.frame(object)[[time]])
}else{
s_pred <- sort(unique(range))
}
df_pred <- df_pred[rep(1, length(s_pred)), ]
df_pred[[time]] <- s_pred
# exract means and variance for group interested
mod_coef <- mod_coef[idx]
mod_cov <- mod_cov[idx, idx]
# prepare design matrix
lpmat <- predict(object, newdata=df_pred, se.fit=TRUE, type = "lpmatrix")
# get mean response by groups with standard errors
pred_df <- df_pred %>% mutate(mean = c(lpmat %*% mod_coef), se = c(sqrt(diag(lpmat %*% mod_cov %*% t(lpmat)))))
length( mod_cov)
dim( mod_cov)
str(mod_coef)
str(lpmat)
idx
idx <- grep("^(Intercept)$|^s\\(seconds\\)\\.[0-9]+$", coef_names)
idx
idx <- grep("^\\(Intercept\\)$|^s\\(seconds\\)\\.[0-9]+$", coef_names)
idx
groups_idx <- unlist(lapply(groups, function(g) grep(g, coef_names)))
idx <- sort(unique(c(idx, groups_idx)))
df_pred[groups] <- 1
df_pred <- df_pred[rep(1, length(s_pred)), ]
df_pred[[time]] <- s_pred
mod_coef <- mod_coef[idx]
mod_cov <- mod_cov[idx, idx]
mod_coef <- object$coefficients
mod_cov <- vcov(object)
mod_coef <- mod_coef[idx]
mod_cov <- mod_cov[idx, idx]
lpmat <- predict(object, newdata=df_pred, se.fit=TRUE, type = "lpmatrix")
# get mean response by groups with standard errors
pred_df <- df_pred %>% mutate(mean = c(lpmat %*% mod_coef), se = c(sqrt(diag(lpmat %*% mod_cov %*% t(lpmat)))))
str(mod_coef)
str(lpmat)
mod_cov <- vcov(object)
dim(mod_cov)
mod_coef <- mod_coef[idx]
mod_cov <- mod_cov[idx, idx]
length(mod_coef)
mod_coef <- object$coefficients
if(model %in% c("gam", "bam")){
mod_cov <- vcov(object) # containing all variance-covariance info for object
}
# get all names for terms
coef_names <- names(mod_coef)
# get index of the initial terms
idx <- grep("^\\(Intercept\\)$|^s\\(seconds\\)\\.[0-9]+$", coef_names)
# initialize dataframe
predictors <- all.vars(formula(object))[-1]
df_pred <- as_tibble(
setNames(
lapply(predictors, function(x) 0),
predictors
)
)
if(!is.null(groups)){
# for group interested
groups_idx <- unlist(lapply(groups, function(g) grep(g, coef_names)))
idx <- sort(unique(c(idx, groups_idx)))
df_pred[groups] <- 1
}
if(!is.null(subject)){
df_pred[subject] <- as.character(model.frame(object)[[subject]][1])
}
if(is.null(range)){
s_pred <- unique(model.frame(object)[[time]])
}else{
s_pred <- sort(unique(range))
}
df_pred <- df_pred[rep(1, length(s_pred)), ]
df_pred[[time]] <- s_pred
# prepare design matrix
lpmat <- predict(object, newdata=df_pred, se.fit=TRUE, type = "lpmatrix")
# get mean response by groups with standard errors
pred_df <- df_pred %>% mutate(mean = c(lpmat %*% mod_coef), se = c(sqrt(diag(lpmat %*% mod_cov %*% t(lpmat)))))
lpmat <- lpmat[, idx]
# exract means and variance for group interested
mod_coef <- mod_coef[idx]
mod_cov <- mod_cov[idx, idx]
# Number of bootstrap samples (B)
if(is.na(nboot)){
nboot <- 1e4
}
# Set up container for bootstrap
yhat_boot <- matrix(NA, nboot, length(s_pred))
for (i in 1:nboot) {
beta_boot_i <- mvrnorm(n = 1, mu = mod_coef, Sigma = mod_cov)
yhat_boot[i, ] <- lpmat %*% beta_boot_i
}
# Find the max statistic
dvec <- apply(yhat_boot, 1, function(x) max(abs(x - pred_df$mean) / pred_df$se)) # Substract mean estimate and divided by Df (element by element)
# Get 95% global confidence band
Z_global <- quantile(dvec, 0.95)
y_hat_LB_global <- pred_df$mean - Z_global * pred_df$se
y_hat_UB_global <- pred_df$mean + Z_global * pred_df$se
global_df <- list(
yhat = pred_df$mean,
time = s_pred,
se_hat = pred_df$se,
scb_low = y_hat_LB_global,
scb_up = y_hat_UB_global,
type = "Global Confidence Interval (CMA)"
)
summary(global_df)
global_df <- as_tibble(global_df)  # 或者 data.frame(global_df)
ggplot(global_df, aes(x = time, y = yhat, color = type)) +
geom_line() +
geom_line(aes(y = scb_low), linetype = 2) +
geom_hline(yintercept = 0, linetype = 3, color = "red") +
theme_minimal() +
labs(
title = "Comparing Confidence Intervals for Non-user Group",
y = "yhat",
x = "Seconds",
color = "Interval Type"
)
ggplot(global_df, aes(x = time, y = yhat, color = type)) +
geom_line() +
geom_line(aes(y = scb_low), linetype = 2) +
geom_hline(yintercept = 0, linetype = 3, color = "red") +
theme_minimal() +
labs(
title = "Comparing Confidence Intervals for Non-user Group",
y = "yhat",
x = "Seconds",
color = "Interval Type"
)
ggplot(global_df, aes(x = time, y = yhat, color = type)) +
geom_line() +
geom_line(aes(y = scb_low), linetype = 2) +
geom_line(aes(y = scb_up), linetype = 2) +
geom_hline(yintercept = 0, linetype = 3, color = "red") +
theme_minimal() +
labs(
title = "Comparing Confidence Intervals for Non-user Group",
y = "yhat",
x = "Seconds",
color = "Interval Type"
)
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
dir.create("inst/extdata", recursive = TRUE, showWarnings = FALSE)
usethis::use_data_raw("climate_data")
library(usethis)
library(readr)
# read .dat file
dat_path <- system.file("extdata", "climate_data.dat", package = "invSCI")
climate_data <- read.table(dat_path, header = TRUE, stringsAsFactors = FALSE)
str(climate_data)
View(climate_data)
lines <- readLines(dat_path, n = 10)
cat(lines, sep = "\n")
readLines(dat_path, n = 5)
readBin(dat_path, what = "raw", n = 100)
load(dat_path)
# read .dat file
dat_path <- system.file("extdata", "climate_data.dat", package = "invSCI")
climate_data <- read.table(dat_path, header = TRUE, stringsAsFactors = FALSE)
str(climate_data)
# read .dat file
dat_path <- system.file("extdata", "climate_data.dat", package = "invSCI")
load(dat_path)
ls()
library(usethis)
library(readr)
# read .dat file
dat_path <- system.file("extdata", "climate_data.dat", package = "invSCI")
load(dat_path)
ls()
load("D:/invSCI/data/ccds.rda")
load("D:/invSCI/data/climate_data.rda")
load("D:/invSCI/data/ccds_fpca.rda")
usethis::use_data_raw("ccds_cma")
here::i_am(
"data-raw/ccds_cma.R"
)
library(here)
library(dplyr)
library(mgcv)
library(tidyr)
library(tibble)
library(refund)
load(here::here("data", "ccds_fpca.rda"))
# obtain the functional regression model object
fosr_mod <- mgcv::bam(percent_change ~ s(seconds, k=30, bs="cr") +
s(seconds, by = use, k=30, bs = "cr") +
s(subject, by = Phi1, bs="re") +
s(subject, by = Phi2, bs="re")+
s(subject, by = Phi3, bs="re") +
s(subject, by = Phi4, bs="re"),
method = "fREML", data = ccds_fpca, discrete = TRUE)
ccds_cma <- cma(fosr_mod, "gam", "seconds", groups = "use", subject = "subject")
summary(ccds_cma)
ccds_cma <- as_tibble(ccds_cma)
usethis::use_data(ccds_cma, overwrite = TRUE)
ccds_cma <- cma(fosr_mod, "gam", "seconds", groups = "use", subject = "subject")
usethis::use_data(ccds_cma, overwrite = TRUE)
ccds_cma <- as_tibble(ccds_cma)
summary(ccds_cma
)
usethis::use_import_from("stats", "lm")
usethis::use_import_from("stats", "predict")
devtools::document()
usethis::use_package("fields")
usethis::use_package("map")
install.packages("map")
install.packages("maps")
install.packages("fields")
install.packages("nlme")
usethis::use_import_from("fields", "image.plot")
usethis::use_import_from("fields", "image.smooth")
usethis::use_import_from("fields", "interp.surface()")
usethis::use_import_from("maps", "map")
library(fields)
ls("package:fields", pattern = "interp")
usethis::use_import_from("fields", "interp.surface")
devtools::document()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
use_r("data_ccds")
library(devtools)
usethis::use_r("data_ccds")
load("D:/invSCI/data/ccds.rda")
load("D:/invSCI/data/ccds_fpca.rda")
load("D:/invSCI/data/climate_data.rda")
devtools::document()
usethis::use_r("data_climate")
devtools::document()
devtools::document()
devtools::document()
usethis::use_data(climate_data, overwrite = TRUE)
library(usethis)
library(readr)
# read .dat file
dat_path <- system.file("extdata", "climate_data.dat", package = "invSCI")
load(dat_path)
ls()
usethis::use_data(climate_data, overwrite = TRUE)
View(epoch)
climate_data <- list(
epoch = epoch,
temp = temp,
orog = orog,
mask = mask,
lat = lat,
lon = lon,
year = year,
current = current,
future = future
)
usethis::use_data(climate_data, overwrite = TRUE)
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
usethis::use_import_from("mgcv", "bam")
devtools::document()
devtools::install()
devtools::load_all()
devtools::install()
devtools::document()
remove.packages("invSCI")
devtools::document()
devtools::install()
devtools::document()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
usethis::use_import_from("mgcv", "bam")
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
get("bam", envir = asNamespace("mgcv"))
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
usethis::use_import_from("ggplot2", "ggplot")
usethis::use_import_from("ggplot2", "aes")
usethis::use_import_from("ggplot2", "geom_line")
usethis::use_import_from("ggplot2", "geom_hline")
usethis::use_import_from("ggplot2", "theme_minimal")
usethis::use_import_from("ggplot2", "labs")
devtools::document()
devtools::install()
devtools::install()
devtools::load_all()
devtools::check()
remove.packages("invSCI")
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
usethis::use_import_from("ggplot2", "theme")
usethis::use_import_from("grDevices", c("contourLines", "hcl.colors"))
usethis::use_import_from("graphics", "lines")
usethis::use_import_from("stats", c("as.formula", "binomial", "cov", "dnorm", "glm",
"model.frame", "qnorm", "rbinom", "rnorm", "runif", "sd",
"time", "var"))
devtools::document()
devtools::install()
devtools::load_all()
devtools::load_all()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
usethis::use_import("ggplot2")
usethis::use_import_from("dplyr", "mutate")
devtools::document()
devtools::install()
devtools::load_all()
remove.packages("invSCI")
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
usethis::use_r("global")
usethis::use_package("mvtnorm", type = "Imports")
usethis::use_import_from("mvtnorm", "rmvnorm")
usethis::use_import_from("reshape", "melt")
usethis::use_import_from("dplyr", c("mutate", "desc"))
usethis::use_import_from("forcats"," fct_reorder")
usethis::use_import_from("forcats","fct_reorder")
devtools::document()
devtools::install()
devtools::load_all()
remove.packages("invSCI")
devtools::document()
devtools::document()
devtools::install()
devtools::load_all()
devtools::check()
devtools::document()
